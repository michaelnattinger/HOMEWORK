% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
\geometry{margin=1in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{amssymb}
\usepackage{amsmath}
%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\usepackage{bbm}

\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\newcount\colveccount
\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{pmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{pmatrix}
        \fi
}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\title{Econometrics HW6}
\author{Michael B. Nattinger\footnote{I worked on this assignment with my study group: Alex von Hafften, Andrew Smith, and Ryan Mather. I have also discussed problem(s) with Emily Case, Sarah Bass, and Danny Edgel.}}

\begin{document}
\maketitle

\section{Question 1} %problem 2 lecture 6
\subsection{Part A}
$P(X=1) = p = p^{1}(1-p)^{1-1} = f(1).$ $P(X=0) = (1-p) = p^0(1-p)^{1-0} = f(0).$
\subsection{Part B}
Our parameter is $\theta = p.$ $l_n(\theta) = \sum_{i=1}^nlog(f(X_i|\theta)) = \sum_{i=1}^nlog(\theta^{X_i}(1-\theta)^{1-X_i})= \sum_{i=1}^nX_i log(\theta) + (1-X_i)log(1-\theta).$
\subsection{Part C}
$\frac{\partial l_n(\theta)}{\partial \theta} = 0 \Rightarrow \sum_{i=1}^n \frac{X_i}{\theta} -\frac{1-X_i}{1-\theta} = 0 \Rightarrow \sum_{i=1}^n X_i(1-\theta) = \sum_{i=1}^n \theta - X_i\theta \Rightarrow  \hat{\theta}_n = \frac{1}{n}\sum_{i=1}^nX_i.$
\section{Question 2} %problem 5 lecture 6
\subsection{Part A}
$l_n(\theta) = \sum_{i=1}^n log\left(\frac{\theta}{X_i^{1+\theta}}\right) = \sum_{i=1}^n log(\theta) - (1+\theta) log(X_i) = nlog(\theta) - (1+\theta) \sum_{i=1}^n log(X_i) $
\subsection{Part B}
$\frac{\partial l_n(\theta)}{\partial \theta} = 0 \Rightarrow \frac{n}{\theta} - \sum_{i=1}^n log(X_i) =0 \Rightarrow \hat{\theta}_n = \frac{n}{\sum_{i=1}^n log(X_i)}  $.
\section{Question 3} %problem 6 lecture 6
\subsection{Part A}
$l_n(\theta) = \sum_{i=1}^n log\left(\frac{1}{\pi(1+(X_i- \theta)^2)}\right) = - nlog(\pi) - \sum_{i=1}^n log(1 +(X_i- \theta)^2) $.
\subsection{Part B}
$\frac{\partial l_n(\theta)}{\partial \theta} = 0 \Rightarrow -\sum_{i=1}^n \frac{2(X_i - \hat{\theta}_n)}{1 +(X_i- \hat{\theta}_n)^2 } = 0$
\section{Question 4} %problem 7 lecture 6
\subsection{Part A}
$l_n(\theta) = \sum_{i=1}^n log(\frac{1}{2} exp(-|X_i-\theta|)) = n log(\frac{1}{2})  -\sum_{i=1}^n |X_i-\theta|$
\subsection{Part B}
The likelihood is maximized when the term $\sum_{i=1}^n |X_i-\theta|$ is minimized. This is minimized for $\theta = M$ where $M$ is the median of the sample, which I will show below:

Let $X_i$ be ordered from smallest to largest. If $n$ is an odd number, define $m = \frac{n+1}{2}$. Then, by the triangle inequality,
\begin{align*}
&\sum_{i=1}^{n}|X_i - \theta| \geq |X_n - \theta - (X_1 - \theta)| + |X_{n-1} - \theta - (X_2 - \theta)| + \dots + |X_{m-1} - \theta - (X_{m+1} - \theta)| + |X_{m} - \theta| \\&= \sum_{i=1}^{m-1} |X_{n+1-i} - X_i| + |X_m - \theta|.
\end{align*}
Clearly, this term is minimized when $\theta=X_m = M$, and the weak inequality holds with equality when $\theta$ is the median because $(X_{n+1-i} - M)\geq 0 \geq( X_i - M)$.

If $n$ is even, we instead define $m=n/2$, and have:
\begin{align*}
&\sum_{i=1}^{n}|X_i - \theta| \geq |X_n - \theta - (X_1 - \theta)| + \dots + |X_{m-1} - \theta - (X_{m+1} - \theta)| + |X_{m} - \theta| +  |X_{m+1} - \theta| \\&= \sum_{i=1}^{m-1} |X_{n+1-i} - X_i| + |X_m - \theta| + |X_{m+1} - \theta|,
\end{align*}
where again our weak inequality holds with equality. In this case, the final expression is clearly minimized for any $\theta \in [X_m,X_{m+1}]$, and $M\in [X_m,X_{m+1}]$.
 % $\theta = E[X]$ and so $\hat{\theta}_n = \frac{1}{n}\sum_{i=1}^n X_i.$
\section{Question 5} %problem 9 lecture 6
$I_0 = -E\left[ \frac{\partial^2}{\partial \theta^2} log(f(X|\theta))|_{\theta = \theta_0}\right] = -E\left[ \frac{\partial^2}{\partial \theta^2} log(\theta x^{-1-\theta})|_{\theta = \theta_0}\right] = -E\left[ \frac{\partial^2}{\partial \theta^2} log(\theta)+(-1-\theta)log(x)|_{\theta = \theta_0}\right] \\ 
= -E\left[ \frac{\partial}{\partial \theta} \frac{1}{\theta}-log(x)|_{\theta = \theta_0}\right] =  -E\left[ \frac{\partial}{\partial \theta} \frac{1}{\theta}-log(x)|_{\theta = \theta_0}\right] = \frac{1}{\theta_0^2}$% = -E\left[ \frac{\partial}{\partial \theta} \alpha(-1-\alpha)x^{-2-\alpha}|_{\theta = \theta_0} \right] = -E\left[ \alpha(-1-\alpha)(-2-\alpha)x^{-3-\alpha}\right] \\= \int_{1}^{\infty}  \alpha(-1-\alpha)(-2-\alpha)x^{-3-\alpha} \alpha x^{-1-\alpha}dx = \alpha^2(-1-\alpha)(-2-\alpha)\int_{1}^{\infty}x^{-4 - 2\alpha}dx \\ = \alpha^2(-1-\alpha)(-2-\alpha)\left( \frac{x^{-3-2\alpha}}{-3-2\alpha} \right)|_{1}^{\infty} = \frac{\alpha^2(-1-\alpha)(-2-\alpha)}{-3-2\alpha}$.
\section{Question 6} %problem 12 lecture 6
\subsection{Part A}
%$S = \frac{\partial}{\partial \theta} log(\theta exp(-\theta x))= \frac{\partial}{\partial \theta} log(\theta)  -\theta x = \frac{1}{\theta} - x.$ $I_0 = -E[S^2] = E[(X- 1/\theta)^2] = \frac{1}{\theta}$
$I_0 = -E\left[ \frac{\partial^2}{\partial \theta^2} log(\theta exp(-\theta x))|_{\theta = \theta_0} \right] = -E\left[ \frac{\partial^2}{\partial \theta^2} log(\theta)+ log(exp(-\theta x)) |_{\theta = \theta_0}\right] \\= -E\left[ \frac{\partial^2}{\partial \theta^2} log(\theta)-\theta x |_{\theta = \theta_0}\right] = \hat{\theta}^{-2}_0 \Rightarrow Var(\bar{\theta}_n) \geq (n \hat{\theta}^{-2}_0)^{-1} = \frac{ \theta^{2}_0}{n}$
\subsection{Part B}
$l_n(\theta) = \sum_{i=1}^nlog(f(X_i|\theta)) = \sum_{i=1}^nlog(\theta exp(-\theta X_i)) = \sum_{i=1}^nlog(\theta)+ log(exp(-\theta X_i)) \\ = nlog(\theta)- \theta\sum_{i=1}^n X_i \Rightarrow \frac{\partial l_n(\theta)}{\partial \theta} = 0 \Rightarrow \frac{n}{\theta} - \sum_{i=1}^n X_i = 0 \Rightarrow \hat{\theta}_n =  \frac{n}{\sum_{i=1}^n X_i}$. 

By the delta method, $\sqrt{n}(\hat{\theta}_n - \theta_0) \rightarrow_d N(0,V)$ where $V = (-1(\theta_0^{-1})^{-2})^2 \sigma^2 = \theta_0^{4}\sigma^2$ where $\sigma^2 = Var(X_i) =  \frac{1}{\theta_0^2}$. Thus, $\sqrt{n}(\hat{\theta}_n - \theta_0) \rightarrow_d N(0,\theta_0^{2})$
\subsection{Part C}
Our general formula is $\sqrt{n}(\hat{\theta}_n - \theta_0) \rightarrow_d N(0,I_0^{-1}) = N(0,\theta_0^2)$.
\section{Question 7} %problem 14 lecture 6
\subsection{Part A}
Via the delta method, $\sqrt{n}(\hat{\theta}_n - \theta_0) \rightarrow_d N(0,V)$ where $V = Var(X_i)= p(1-p).$ Thus, a consistent estimator for $V$ will be a consistent estimator of $Var(X_i).$ A consistent estimator of the variance is $\hat{V} := (\frac{1}{n}\sum_{i=1}^{n}(X_i ))(1-\frac{1}{n}\sum_{i=1}^{n}(X_i ))$.
\subsection{Part B}
The WLLN and CMT imply that $\hat{V} \rightarrow_p p(1-p) = Var(X_i) = V$. Thus, $\hat{V}$ is a consistent estimator of $V$.
\subsection{Part C}
We have that the asymptotic variance of $\sqrt{n}(\hat{\theta}_n - \theta_0)$ is consistently estimated by $(\frac{1}{n}\sum_{i=1}^{n}(X_i ))(1-\frac{1}{n}\sum_{i=1}^{n}(X_i )).$ Therefore, an approximation of $Var(\hat{\theta}_n) =\frac{1}{n}Var(\sqrt{n}\hat{\theta}_n) = \frac{1}{n}Var(\sqrt{n}(\hat{\theta}_n - \theta_0))$ so an estimator of $Var(\hat{\theta}_n)$ is $\frac{1}{n}((\frac{1}{n}\sum_{i=1}^{n}(X_i ))(1-\frac{1}{n}\sum_{i=1}^{n}(X_i ))).$
\section{Question 8} %problem 15 lecture 6
\subsection{Part A}
$F_X(c) = \int_{-\infty}^c f_X(x)dx = \begin{cases} 0, c<0 \\ G(c), 0\leq c \leq \theta \\1, c>\theta \end{cases}$ where $G(c) = \int_{0}^c \frac{1}{\theta} dx = \frac{c}{\theta}.$
\subsection{Part B}
$F_{n(\hat{\theta}_n - \theta)}(x) = Pr(\max_{i=1,\dots,n}(n(X_i - \theta))\leq x) = Pr(n(X_1 - \theta) \leq x,\dots,n(X_n - \theta) \leq x) = \prod_{i=1}^n Pr(n(X_i - \theta)\leq x) = \prod_{i=1}^nPr(X_i\leq \theta + \frac{x}{n}) = Pr(X_i\leq \theta + \frac{x}{n})^n = (F_X(\theta + \frac{x}{n}))^n.$
\subsection{Part C}
Fix $x$. For $x<0$, $F_{n(\hat{\theta}_n - \theta)}(x) =(F_X(\theta + \frac{x}{n}))^n = (F_X(\theta(1 + \frac{x/\theta}{n})))^n  \rightarrow_{n\rightarrow \infty} \lim_{n\rightarrow \infty} ((\theta(1 + \frac{x/\theta}{n}))/\theta)^n = e^{x/\theta} $.

For $x>0, F_{n(\hat{\theta}_n - \theta_0)} = (F_{X}(\theta + \frac{x}{n}))^n = 1^n =1$ so $\lim_{n\rightarrow \infty}F_{n(\hat{\theta}_n - \theta)} = 1.$
\subsection{Part D}
$\lim_{n\rightarrow \infty}f_{n(\hat{\theta}_n - \theta)}(x) =\lim_{n\rightarrow \infty} \frac{\partial}{\partial x}F_{n(\hat{\theta}_n - \theta)}(x) = \frac{1}{\theta}e^{x/\theta}  $ for $x\leq0 \Rightarrow \lim_{n\rightarrow \infty}f_{n(\hat{\theta}_n - \theta)}(-x) = \frac{1}{\theta}e^{-x/\theta} $ so $n(\hat{\theta}_n - \theta)\rightarrow_d -A$ where distribution A is an exponential with parameter $\theta$.

\section{Question 9} %problem 1 lecture 7
We should use a two-sided test. We will calculate $t = \frac{\bar{X}_n - 1}{se},se = \sqrt{s^2/n}.$ For a chosen significance level $\alpha$ we can reject the null hypothesis if $P(|T|> t) < \alpha/2$, where $t \sim t_{n-1}$.

\section{Question 10}  %problem 3 lecture 7
Assume $\mu = 1.$ Then, $X_i \sim N(1,1) \Rightarrow \sqrt{n}(\bar{X}_n - 1) \sim N(0,1)$ by WLLN, CLT $\Rightarrow |\sqrt{n}(\bar{X}_n - 1)| \sim |N(0,1)|.$ Also, $\sqrt{n}(\bar{X}_n - 1) \sim N(0,1) \Rightarrow \sqrt{n}\bar{X}_n \sim N(\sqrt{n},1) \Rightarrow |\sqrt{n}\bar{X}_n| \sim |N(\sqrt{n},1)| = |N(0,1) + \sqrt{n}|$.

Therefore, $P(T>c|\mu =1) = P(\min \{|\sqrt{n}\bar{X}_n|,|\sqrt{n}(\bar{X}_n - 1)| \}>c|\mu = 1) = P(\min \{ |Z|,|Z - \sqrt{n}|\}) = \alpha$.

Assume $\mu = 0.$ Then, $X_i \sim N(0,1) \Rightarrow \sqrt{n}(\bar{X}_n ) \sim N(0,1)$ by WLLN, CLT $\Rightarrow |\sqrt{n}(\bar{X}_n )| \sim |N(0,1)|.$ Also, $\sqrt{n}(\bar{X}_n ) \sim N(0,1) \Rightarrow \sqrt{n}\bar{X}_n -\sqrt{n} \sim N(-\sqrt{n},1) \Rightarrow |\sqrt{n}\bar{X}_n -\sqrt{n}| \sim |N(-\sqrt{n},1)| = |N(\sqrt{n},1)| = |N(0,1) + \sqrt{n}|$.

Therefore, $P(T>c|\mu =0) = P(\min \{|\sqrt{n}\bar{X}_n|,|\sqrt{n}(\bar{X}_n - 1)| \}>c|\mu = 0) = P(\min \{ |Z|,|Z - \sqrt{n}|\}) = \alpha$.

Thus, the size of the test is $\alpha$.
\end{document}
